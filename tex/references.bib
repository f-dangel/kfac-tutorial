@incollection{paszke2019pytorch,
  title =        {{PyTorch}: An Imperative Style, High-Performance Deep Learning
                  Library},
  author =       {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer,
                  Adam and Bradbury, James and Chanan, Gregory and Killeen,
                  Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga,
                  Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward
                  and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and
                  Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai,
                  Junjie and Chintala, Soumith},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2019,
}

@article{pearlmutter1994fast,
  author =       {Pearlmutter, Barak A.},
  title =        {Fast Exact Multiplication by the {H}essian},
  journal =      {Neural Computation},
  year =         1994,
}

@InProceedings{martens2015optimizing,
  title =        {Optimizing Neural Networks with {K}ronecker-factored
                  Approximate Curvature},
  author =       {Martens, James and Grosse, Roger},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2015,
}

@inproceedings{grosse2016kroneckerfactored,
  author =       {Grosse, Roger and Martens, James},
  title =        {A Kronecker-Factored Approximate {F}isher Matrix for
                  Convolution Layers},
  year =         2016,
  booktitle =    {International Conference on Machine Learning (ICML)},
}

@inproceedings{martens2018kroneckerfactored,
  title =        {Kronecker-factored Curvature Approximations for Recurrent
                  Neural Networks},
  author =       {James Martens and Jimmy Ba and Matt Johnson},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2018,
}

@inproceedings{eschenhagen2023kroneckerfactored,
  title =        {Kronecker-Factored Approximate Curvature for Modern Neural
                  Network Architectures},
  author =       {Runa Eschenhagen and Alexander Immer and Richard E. Turner and
                  Frank Schneider and Philipp Hennig},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2023,
}

@InProceedings{dangel2020modular,
  title =        {Modular Block-diagonal Curvature Approximations for
                  Feedforward Architectures},
  author =       {Dangel, Felix and Harmeling, Stefan and Hennig, Philipp},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2020,
}

@inproceedings{papyan2019measurements,
  author =       {Vardan Papyan},
  title =        {Measurements of Three-Level Hierarchical Structure in the
                  Outliers in the Spectrum of Deepnet {H}essians},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2019,
}

@article{schraudolph2002fast,
  title =        {Fast curvature matrix-vector products for second-order
                  gradient descent},
  author =       {Schraudolph, Nicol N},
  journal =      {Neural Computation},
  year =         2002,
}

@article{dangel2022vivit,
  title =        {Vi{V}i{T}: Curvature Access Through The Generalized
                  Gauss-Newton{\textquoteright}s Low-Rank Structure},
  author =       {Felix Dangel and Lukas Tatzel and Philipp Hennig},
  journal =      {Transactions on Machine Learning Research (TMLR)},
  year =         2022,
}

@article{dangel2023backpropagation,
  title =        {Backpropagation Beyond the Gradient},
  author =       {Dangel, Felix},
  year =         2023,
  school =       {Universit{\"a}t T{\"u}bingen}
}

@inproceedings{bernacchia2018exact,
  author =       {Bernacchia, Alberto and Lengyel, Mate and Hennequin,
                  Guillaume},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  title =        {Exact natural gradient in deep linear networks and its
                  application to the nonlinear case},
  year =         2018,
  tags =         {vivit},
}

@inproceedings{petersen2023isaac,
  title =        {{ISAAC} Newton: Input-based Approximate Curvature for Newton's
                  Method},
  author =       {Felix Petersen and Tobias Sutter and Christian Borgelt and
                  Dongsung Huh and Hilde Kuehne and Yuekai Sun and Oliver
                  Deussen},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2023,
}

@inproceedings{dangel2024kroneckerfactored,
  title =        {Kronecker-Factored Approximate Curvature for Physics-Informed
                  Neural Networks},
  author =       {Felix Dangel and Johannes MÃ¼ller and Marius Zeinhofer},
  year =         2024,
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  keywords =     {mywork},
}

@article{kunstner2019limitations,
  title =        {Limitations of the Empirical Fisher Approximation for Natural
                  Gradient Descent},
  author =       {Kunstner, Frederik and Hennig, Philipp and Balles, Lukas},
  year =         2019,
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{lin2024can,
  title =        {Can We Remove the Square-Root in Adaptive Gradient Methods?
                  {A} Second-Order Perspective},
  author =       {Lin, Wu and Dangel, Felix and Eschenhagen, Runa and Bae, Juhan
                  and Turner, Richard E. and Makhzani, Alireza},
  year =         2024,
  booktitle =    {International Conference on Machine Learning (ICML)},
}
