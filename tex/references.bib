@incollection{paszke2019pytorch,
  title =        {{PyTorch}: An Imperative Style, High-Performance Deep Learning
                  Library},
  author =       {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer,
                  Adam and Bradbury, James and Chanan, Gregory and Killeen,
                  Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga,
                  Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward
                  and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and
                  Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai,
                  Junjie and Chintala, Soumith},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2019,
}

@article{pearlmutter1994fast,
  author =       {Pearlmutter, Barak A.},
  title =        {Fast Exact Multiplication by the {H}essian},
  journal =      {Neural Computation},
  year =         1994,
}

@InProceedings{martens2015optimizing,
  title =        {Optimizing Neural Networks with {K}ronecker-factored
                  Approximate Curvature},
  author =       {Martens, James and Grosse, Roger},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2015,
}

@inproceedings{grosse2016kroneckerfactored,
  author =       {Grosse, Roger and Martens, James},
  title =        {A Kronecker-Factored Approximate {F}isher Matrix for
                  Convolution Layers},
  year =         2016,
  booktitle =    {International Conference on Machine Learning (ICML)},
}

@inproceedings{martens2018kroneckerfactored,
  title =        {Kronecker-factored Curvature Approximations for Recurrent
                  Neural Networks},
  author =       {James Martens and Jimmy Ba and Matt Johnson},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2018,
}

@inproceedings{eschenhagen2023kroneckerfactored,
  title =        {Kronecker-Factored Approximate Curvature for Modern Neural
                  Network Architectures},
  author =       {Runa Eschenhagen and Alexander Immer and Richard E. Turner and
                  Frank Schneider and Philipp Hennig},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2023,
}

@InProceedings{dangel2020modular,
  title =        {Modular Block-diagonal Curvature Approximations for
                  Feedforward Architectures},
  author =       {Dangel, Felix and Harmeling, Stefan and Hennig, Philipp},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS)},
  year =         2020,
}

@inproceedings{papyan2019measurements,
  author =       {Vardan Papyan},
  title =        {Measurements of Three-Level Hierarchical Structure in the
                  Outliers in the Spectrum of Deepnet {H}essians},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2019,
}

@article{schraudolph2002fast,
  title =        {Fast curvature matrix-vector products for second-order
                  gradient descent},
  author =       {Schraudolph, Nicol N},
  journal =      {Neural Computation},
  year =         2002,
}

@article{dangel2022vivit,
  title =        {Vi{V}i{T}: Curvature Access Through The Generalized
                  Gauss-Newton{\textquoteright}s Low-Rank Structure},
  author =       {Felix Dangel and Lukas Tatzel and Philipp Hennig},
  journal =      {Transactions on Machine Learning Research (TMLR)},
  year =         2022,
}

@article{dangel2023backpropagation,
  title =        {Backpropagation Beyond the Gradient},
  author =       {Dangel, Felix},
  year =         2023,
  school =       {Universit{\"a}t T{\"u}bingen}
}

@inproceedings{bernacchia2018exact,
  author =       {Bernacchia, Alberto and Lengyel, Mate and Hennequin,
                  Guillaume},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  title =        {Exact natural gradient in deep linear networks and its
                  application to the nonlinear case},
  year =         2018,
  tags =         {vivit},
}

@inproceedings{petersen2023isaac,
  title =        {{ISAAC} Newton: Input-based Approximate Curvature for Newton's
                  Method},
  author =       {Felix Petersen and Tobias Sutter and Christian Borgelt and
                  Dongsung Huh and Hilde Kuehne and Yuekai Sun and Oliver
                  Deussen},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2023,
}

@inproceedings{dangel2024kroneckerfactored,
  title =        {Kronecker-Factored Approximate Curvature for Physics-Informed
                  Neural Networks},
  author =       {Felix Dangel and Johannes Müller and Marius Zeinhofer},
  year =         2024,
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  keywords =     {mywork},
}

@article{kunstner2019limitations,
  title =        {Limitations of the Empirical Fisher Approximation for Natural
                  Gradient Descent},
  author =       {Kunstner, Frederik and Hennig, Philipp and Balles, Lukas},
  year =         2019,
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{lin2024can,
  title =        {Can We Remove the Square-Root in Adaptive Gradient Methods?
                  {A} Second-Order Perspective},
  author =       {Lin, Wu and Dangel, Felix and Eschenhagen, Runa and Bae, Juhan
                  and Turner, Richard E. and Makhzani, Alireza},
  year =         2024,
  booktitle =    {International Conference on Machine Learning (ICML)},
}

@article{dangel2025position,
  title =        {Position: Curvature Matrices Should Be Democratized via Linear
                  Operators},
  author =       {Dangel, Felix and Eschenhagen, Runa and Ormaniec, Weronika and
                  Fernandez, Andres and Tatzel, Lukas and Kristiadi, Agustinus},
  journal =      {arXiv},
  year =         2025
}

@inproceedings{daxberger2021laplace,
  title =        {Laplace Redux - Effortless Bayesian Deep Learning},
  author =       {Erik Daxberger and Agustinus Kristiadi and Alexander Immer and
                  Runa Eschenhagen and Matthias Bauer and Philipp Hennig},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2021,
}

@inproceedings{bae2024training,
  title =        {Training Data Attribution via Approximate Unrolling},
  author =       {Juhan Bae and Wu Lin and Jonathan Lorraine and Roger Baker
                  Grosse},
  booktitle =    {Advances in Neural Information Processing Systems (NeurIPS)},
  year =         2024,
}

@misc{grosse2023studying,
  title =        {Studying Large Language Model Generalization with Influence
                  Functions},
  author =       {Roger Grosse and Juhan Bae and Cem Anil and Nelson Elhage and
                  Alex Tamkin and Amirhossein Tajdini and Benoit Steiner and
                  Dustin Li and Esin Durmus and Ethan Perez and Evan Hubinger
                  and Kamilė Lukošiūtė and Karina Nguyen and Nicholas Joseph and
                  Sam McCandlish and Jared Kaplan and Samuel R. Bowman},
  year =         2023,
}

@article{tam2024merging,
  title =        {Merging by Matching Models in Task Parameter Subspaces},
  author =       {Derek Tam and Mohit Bansal and Colin Raffel},
  journal =      {Transactions on Machine Learning Research (TMLR)},
  year =         2024,
}

@inproceedings{benzing2022gradient,
  title =        {Gradient Descent on Neurons and its Link to Approximate
                  Second-order Optimization},
  author =       {Benzing, Frederik},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2022,
}

@inproceedings{wang2019eigendamage,
  title =        {Eigendamage: Structured pruning in the kronecker-factored
                  eigenbasis},
  author =       {Wang, Chaoqi and Grosse, Roger and Fidler, Sanja and Zhang,
                  Guodong},
  booktitle =    {International Conference on Machine Learning (ICML)},
  year =         2019,
}

@misc{osawa2023asdl,
  title =        {ASDL: A Unified Interface for Gradient Preconditioning in
                  PyTorch},
  author =       {Kazuki Osawa and Satoki Ishikawa and Rio Yokota and Shigang Li
                  and Torsten Hoefler},
  year =         2023,
}

@software{botev2022kfac-jax,
  author = {Aleksandar Botev and James Martens},
  title = {{KFAC-JAX}},
  url = {https://github.com/google-deepmind/kfac-jax},
  version = {0.0.2},
  year = {2022},
}

@article{george2018fast,
  title =        {Fast Approximate Natural Gradient Descent in a
                  Kronecker-factored Eigenbasis},
  author =       {Thomas George and César Laurent and Xavier Bouthillier and
                  Nicolas Ballas and Pascal Vincent},
  year =         2018,
  journal =      {Advances in Neural Information Processing Systems (NeurIPS)},
}

@inproceedings{dangel2020backpack,
  title =        {{B}ack{PACK}: Packing more into Backprop},
  author =       {Felix Dangel and Frederik Kunstner and Philipp Hennig},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2020,
}

@misc{townsend2017new,
  author =       {James Townsend},
  title =        {A new trick for calculating Jacobian vector products},
  year =         2017,
  howpublished = {\url{https://j-towns.github.io/2017/06/12/A-new-trick.html}},
  note =         {Accessed: 2025-03-22}
}

@misc{brunet2010basics,
  author =       {Florent Brunet},
  year =         2010,
  title =        {Basics on Continuous Optimization},
  howpublished = {\url{https://www.brnt.eu/phd/node10.html}},
  note =         {Accessed: 2025-03-22}
}

@article{ren2019efficient,
  title =        {Efficient Subsampled Gauss-Newton and Natural Gradient Methods
                  for Training Neural Networks},
  author =       {Yi Ren and Donald Goldfarb},
  year =         2019,
  journal =      {arXiv},
}

@article{soen2024tradeoffs,
  title =        {Tradeoffs of Diagonal Fisher Information Matrix Estimators},
  author =       {Soen, Alexander and Sun, Ke},
  year =         2024
}

@article{papyan2020traces,
  author =       {Vardan Papyan},
  title =        {Traces of Class/Cross-Class Structure Pervade Deep Learning
                  Spectra},
  journal =      {Journal of Machine Learning Research (JMLR)},
  year =         2020,
}

@inproceedings{kingma2015adam,
  title =        {{A}dam: A Method for Stochastic Optimization},
  author =       {Kingma, Diederik P and Ba, Jimmy},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2015
}

@article{reed2022torch,
  title =        {torch.fx: Practical program capture and transformation for
                  deep learning in python},
  author =       {Reed, James and DeVito, Zachary and He, Horace and Ussery,
                  Ansley and Ansel, Jason},
  journal =      {Proceedings of Machine Learning and Systems (MLSys)},
  year =         2022
}

@inproceedings{duffield2025scalable,
  title =        {Scalable Bayesian Learning with posteriors},
  author =       {Duffield, Samuel and Donatella, Kaelan and Chiu, Johnathan and
                  Klett, Phoebe and Simpson, Daniel},
  booktitle =    {International Conference on Learning Representations (ICLR)},
  year =         2025
}
