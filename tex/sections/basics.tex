\switchcolumn[1]*
\codeblock{basics/reduction_factors}
\switchcolumn[0]

This tutorial is meant to be self-contained.
Therefore, we will start with an extensive introduction to KFAC-relevant concepts.
This allows us to build the code functionality we will later need to verify our implementation.

\paragraph{Roadmap.} First, we introduce the empirical risk (`the loss', \cref{subsec:empirical-risk-minimization}) whose curvature KFAC approximates, and neural networks (\cref{subsec:deep-neural-networks}).
One recurring theme in our discussion will be that the loss and neural net have probabilistic interpretations in most deep learning settings: Minimizing the empirical risk corresponds to maximum likelihood estimation where the neural net models a likelihood (\cref{subsec:probabilistic-interpretation}).
Next, since curvature information is based on the Hessian which contains second-order partial derivatives, we will talk about first- and second-order derivatives, and how to compute with them using PyTorch's automatic differentiation (\cref{subsec:derivatives}).
We conclude with an introduction to all curvature matrices relevant to our discussion (\cref{subsec:curvature-matrices}).
These include the Hessian, generalized Gauss-Newton (GGN) matrix and different flavours of the Fisher information matrix which follows from the probabilistic interpretation from \cref{subsec:probabilistic-interpretation}.

\subsection{Empirical Risk Minimization}\label{subsec:empirical-risk-minimization}
\input{sections/basics_empirical_risk.tex}

\switchcolumn[1]
\codeblock{basics/forward_pass}
\switchcolumn[0]

\subsection{Deep Neural Networks}\label{subsec:deep-neural-networks}
\input{sections/basics_neural_networks.tex}

\subsection{Probabilistic Interpretation}\label{subsec:probabilistic-interpretation}
\input{sections/basics_probabilistic_interpretation.tex}

\subsection{Derivatives \& Automatic Differentiation}\label{subsec:derivatives}

\begin{caveat}
  In deep learning, we often work with matrices, or higher-dimensional tensors.
  We want to use matrix linear algebra expressions to avoid using heavy index notation.
  This can be achieved by flattening all tensors back into vectors and re-using definitions of derivatives from the vector case.
  However, we must be careful when translating the results back to the tensor format, as the translation process depends on the flattening convention.
  Classically, the mathematical derivations prefer a \emph{different} flattening scheme than the one used in deep learning libraries.
\end{caveat}

\switchcolumn[0]*
\subsubsection{Flattening}
\input{sections/basics_flattening.tex}

\switchcolumn[0]*
\subsubsection{Jacobians, JVP, VJPs}
\input{sections/basics_jacobians.tex}

\switchcolumn[0]*
\subsubsection{Hessians, HVPs}
\input{sections/basics_hessians.tex}

\switchcolumn[0]*
\subsubsection{Partial Linearization, Generalized Gauss-Newtons, GGNVPs}\label{sec:partial_linearization}
\input{sections/basics_linearization.tex}

\switchcolumn[0]*
\subsection{Curvature Matrices in Deep Learning}\label{subsec:curvature-matrices}

The previous section introduced Jacobians, Hessians, partial linearizations and the resulting generalized Gauss-Newton (GGN) objects in the language of automatic differentiation for arbitrary functions.
Here, we will switch gears and quickly walk through how these matrices look like in the context of deep learning.

\switchcolumn[1]
\codeblock{basics/hessian_factorizations}
\switchcolumn[0]

\paragraph{Parameter list/tuple format:} One new aspect we have to deal with is that ML libraries like PyTorch represent parameters as lists/tuples of variables.
We consider a neural network $f(\vtheta, x): \Theta \times \gX \to \gF$ with parameters in list/tuple-format,
\begin{align*}
  \vtheta = (\vtheta^{(1)}, \vtheta^{(2)}, \ldots, \vtheta^{(L)}),
\end{align*}
where each $\vtheta^{(i)}$ is an arbitrary tensor. To be able to use matrix expressions, we will often consider the concatenation of flattened vectors,
\begin{align*}
  \vec(\vtheta)
  =
  \begin{pmatrix}
    \vec(\vtheta^{(1)}) \\
    \vec(\vtheta^{(2)}) \\
    \vdots              \\
    \vec(\vtheta^{(L)})
  \end{pmatrix}
  \in \sR^D
  \,,
\end{align*}
where $\vec \in \{ \rvec, \cvec \}$ is one of the previously described flattening operations.
This convention allows $\vec$ to handle parameters in list/tuple format, and is a simple generalization which applies the original definition to each element of the list/tuple and concatenates all flattened items.
However, in code we will still work with the list/tuple format.

\paragraph{Empirical risk:} We consider a data set $\sD = \{(\vx_n, \vy_n) \in \gX \times \gY \mid n = 1, \dots, N \}$ containing $N$ independent and identically distributed (i.i.d.)\,samples.
The inputs are processed by the neural network $f: \Theta \times \gX \to \gF$ and the resulting predictions are scored with a criterion function $c: \gF \times \gY \to \sR$, such as mean-squared or softmax cross-entropy loss.
For a datum $n$, we define the per-datum loss as:
\begin{align*}
  (\ell_n: \Theta \to \sR) = (c_n \circ f_n: \Theta \to \gF \to \sR)
  \\
  \ell_n(\vtheta) = c_n(f_n(\vtheta))
\end{align*}
where $c_n(\bullet) \coloneq c(\bullet, \vy_n)$ and $f_n(\bullet) \coloneq f(\bullet, \vx_n)$.
We will often use the shorthands $c_n, f_n, \ell_n$ for the per-datum criteria, predictions, and losses, respectively.

\paragraph{Reduction factor:} The per-datum losses $\{\ell_1, \dots, \ell_N\}$ are accumulated into a single scalar which yields the empirical risk
\begin{align*}
  \gL_{\sD}: \Theta & \mapsto \sR
  \\
  \vtheta           & \mapsto \gL_{\sD}(\vtheta) = R \sum_{n=1}^N \ell_n(\vtheta) = R \sum_{n=1}^N c_n(f_n(\vtheta))
\end{align*}
where $R$ is the reduction factor. Common values for $R$ are $\nicefrac{1}{N}, 1$ and $\nicefrac{1}{N \dim(\gF)}$.
For the purpose of this text, $\sD$ can be any collection of data points, e.g.\,the full data set or a mini-batch.

\subsubsection{The Hessian}\label{sec:basics_dl_hessian}
\input{sections/basics_dl_hessian.tex}

\subsubsection{The Generalized Gauss-Newton (GGN)}
\input{sections/basics_dl_ggn.tex}

\subsubsection{The Fisher}\label{sec:fisher}
\input{sections/basics_dl_fisher.tex}

\subsubsection{The Connection between GGN \& Fisher}
The GGN, type-I and type-II Fisher can all be written as weighted sum over matrices sandwiched between the per-sample Jacobians (remember that we can mentally set $-\log r(\rvy \mid \vf_n) = c(\vf_n, \rvy)$ for square and softmax cross-entropy loss):
\begin{align*}
  \mG(\vtheta)
   & =
  R \sum_n
  \begin{aligned}[t]
     & (\jac_{\vtheta}\vf_n)^\top                           \\
     & \textcolor{VectorBlue}{\hess_{\vf_n}c(\vf_n, \vy_n)} \\
     & \jac_{\vtheta}\vf_n
  \end{aligned}
  \\
  \mF^{\text{II}}(\vtheta)
   & =
  R \sum_n
  \begin{aligned}[t]
     & (\jac_{\vtheta}\vf_n)^\top                                                                 \\
     & \textcolor{VectorPink}{\E_{r(\rvy \mid \vf_n)}[-\hess_{\vf_n} \log( r(\rvy \mid \vf_n)) ]} \\
     & \jac_{\vtheta}\vf_n
  \end{aligned}
  \\
  \mF^{\text{I}}(\vtheta)
   & =
  R \sum_n
  \begin{aligned}[t]
     & (\jac_{\vtheta}\vf_n)^\top                          \\
     & \textcolor{VectorTeal}{\E_{r(\rvy \mid \vf_n)}[
    \begin{aligned}[t]
       & -\nabla_{\vf_n} \log( r(\rvy \mid \vf_n))           \\
       & (-\nabla_{\vf_n} \log( r(\rvy \mid \vf_n)))^{\top}]
    \end{aligned}} \\
     & \jac_{\vtheta}\vf_n
  \end{aligned}
\end{align*}
In previous sections, we already showed that for square loss and softmax cross-entropy the criterion function's Hessian $\hess_\vf c(\vf, \vy) = -\hess_{\vf} \log( r(\rvy = \vy \mid \vf)$ does not depend on the value of the target random variable $\rvy$!
Therefore, the expectation in the type-II Fisher effectively disappears and we are free to set $\rvy = \vy_n$ because this does not change the Hessian.
This means the type-II Fisher is equivalent to the GGN for square loss and softmax cross-entropy.
Note that we cannot drop the expectation in the type-I Fisher, though.\footnote{This is precisely why we needed a separate definition for the Monte-Carlo-approximated type-I Fisher,
as it yields different values from the type-II Fisher even for the square and softmax cross-entropy losses.}
But from the equivalence of type-I and type-II Fisher, we know that it also equals the GGN in the above scenarios.

\subsubsection{The Empirical Fisher (EF)}\label{sec:emp_fisher}
\input{sections/basics_dl_emp_fisher.tex}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
