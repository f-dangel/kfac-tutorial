So far, we have considered minimizing an empirical risk over a data set given an arbitrary criterion function $c$.
Now, we take a step back and first describe empirical risk minimization as an approximation of minimizing the intractable population risk.
This perspective connects to a probabilistic interpretation of empirical risk minimization as maximum likelihood estimation that will occur throughout the tutorial, \eg when we define the Fisher information matrix as curvature matrix (\cref{subsec:curvature-matrices}).

\paragraph{Empirical risk as expectation.} Recall the empirical risk from \cref{eq:empirical_risk} which we minimize during training,
\begin{align*}
  \min_{\vtheta} \gL_{\sD}(\vtheta) = \min_{\vtheta} R \sum_{n=1}^N \ell_n(\vtheta)\,.
\end{align*}
Why is it called an `empirical' risk?
Because it can be expressed as expectation over an empirical distribution in the following sense:

Assume there exists a data-generating process $p_{\text{data}}(\rvx, \rvy)$ over input-target pairs.
Ideally, we want to minimize the risk over this distribution,
\begin{align*}
  \argmin_{\vtheta} \E_{(\vx, \vy) \sim p_{\text{data}}(\rvx, \rvy)}[c(f(\vx, \vtheta), \vy)]\,.
\end{align*}
However, $p_{\text{data}}$ is intractable.
Therefore, we draw a finite collection of samples into a data set
\begin{align*}
  \sD = \{ (\vx_n, \vy_n) \mid (\vx_n, \vy_n) \stackrel{\text{\iid}}{\sim} p_{\text{data}}(\vx, \vy) \}\,.
\end{align*}
Then, we can replace the intractable data-generating process $p_{\text{data}}$ with the tractable empirical distribution $p_{\sD}(\rvx, \rvy)$ implied by data set $\sD$.
It consists of a uniformly weighted sum of delta peaks around the collected data points,
\begin{align*}
  p_{\sD}(\rvx, \rvy) = \frac{1}{N} \sum_{n=1}^N \delta(\rvx - \vx_n) \delta(\rvy - \vy_n)\,.
\end{align*}
This turns risk minimization into a tractable task:
\begin{align*}
  & \argmin_{\vtheta} \E_{(\vx, \vy) \sim \colored{p_{\text{data}}(\rvx, \rvy)}}[c(f(\vx, \vtheta), \vy)]
  \\
  \approx & \argmin_{\vtheta} \E_{(\vx, \vy) \sim \colored{p_{\sD}(\rvx, \rvy)}}[c(f(\vx, \vtheta), \vy)].
  \\
  \intertext{By writing out the expectation, we obtain}
  =       & \argmin_{\vtheta} \frac{1}{N} \sum_n c(f(\vx_n, \vtheta), \vy_n).
  \\
  \intertext{Note that the minimized objective is the empirical risk in \cref{eq:empirical_risk}
  scaled by $\nicefrac{1}{NR}$.
  However, we can arbitrarily scale objectives without changing the
  location of their minima.
  Hence, the above is equivalent to minimizing the empirical risk
  }
  =& \argmin_{\vtheta} \gL_{\sD}(\vtheta)\,.
\end{align*}
We have thus shown that empirical risk minimization is minimizing a (scaled) expectation of the criterion $c$ over an empirical density $p_{\sD}(\rvx, \rvy)$.

\paragraph{The neural net parameterizes a likelihood.}
Let's approach this from a probabilistic perspective now.
Assume we want to learn $p_{\text{data}}(\rvx, \rvy) = p_{\text{data}}(\rvy \mid \rvx) p_{\text{data}}(\vx)$ using a parameterized density of the form $p(\rvx, \rvy \mid \vtheta) = p(\rvy \mid \rvx, \vtheta) p_{\text{data}}(\rvx)$ where $p_{\text{data}}(\rvx) = \int p_{\text{data}}(\rvx, \rvy)\ \mathrm{d}\rvy$ is the marginal density of the input data.
Note that we only model the likelihood of the labels with parameters $\vtheta$.

One plausible approach to make $p$ resemble $p_{\text{data}}$ is to minimize their KL divergence,
\begin{align*}
  & \argmin_{\vtheta} \mathrm{KL}(p_{\text{data}}(\rvx, \rvy) \mid\mid p(\rvx, \rvy \mid \vtheta))\,.
  \\
  \intertext{We can simplify this expression by substituting the definition of the KL divergence and dropping terms that do not depend on $\vtheta$,}
  \Leftrightarrow & \argmin_{\vtheta} \E_{p_{\text{data}}(\rvx, \rvy)}[- \log( p(\rvx, \rvy \mid \vtheta))]\,.
  \\
  \intertext{This looks very similar to the expected risk from above.
  Next, let's factorize our model distribution using its conditional and marginal densities and drop $p_{\text{data}}(\rvx)$ as it does not depend on $\vtheta$,
  }
  \Leftrightarrow & \argmin_{\vtheta} \E_{p_{\text{data}}(\rvx, \rvy)}[- \log( p(\rvy \mid \rvx, \vtheta))]\,.
                    \intertext{To make this problem tractable, we need to replace the intractable data-generating process $p_{\text{data}}(\rvx, \rvy)$ with the empirical distribution $p_{\sD}(\rvx, \rvy)$ again:}
                    \approx         & \argmin_{\vtheta} \E_{p_{\sD}(\rvx, \rvy)}[- \log( p(\rvy \mid \rvx, \vtheta))].
  \\
  \intertext{Writing out the expectation, we obtain}
  =               & \argmin_{\vtheta} \frac{1}{N} \sum_n - \log( p(\rvy = \vy_n \mid \rvx=\vx_n,\vtheta)).
  \\
  \intertext{To make this expression more similar to the empirical risk, we introduce a general scaling $R$ and change the likelihood's parameterization from $p(\rvy \mid \rvx, \vtheta)$ to $r(\rvy \mid f(\rvx, \vtheta))$ with a neural net $f$:}
  =               & \argmin_{\vtheta} R \sum_n - \log( r(\rvy = \vy_n \mid f(\vx_n,\vtheta)))
\end{align*}
This parameterization makes it clear that the neural network represents a conditional distribution over the labels given the inputs (and parameters).

\paragraph{The criterion is the negative log-likelihood.}
We are now very close to writing down the explicit connection between empirical risk minimization and maximum likelihood estimation.
The last remaining step is to connect the model's likelihood $r(\rvy \mid f(\rvx, \vtheta))$ with the criterion function $c(f(\vx, \vtheta), \vy)$ from empirical risk minimization.
It turns out that empirical risk minimization with square loss (\cref{ex:square_loss}) corresponds to maximum likelihood estimation (or equivalently, negative log-likelihood minimization) of a Gaussian distribution over the labels (\cref{ex:square_loss_probabilistic}).
Similarly, classification with softmax cross-entropy criterion amounts to maximum likelihood estimation where the neural net parameterizes a categorical distribution (\cref{ex:cross_entropy_loss_probabilistic}).
\Cref{basics/label_sampling} provides functions to sample labels from these distributions.

The neural net's interpretation as a likelihood allows using probabilistic concepts to measure similarity for comparing two networks.
This will be useful when we define the Fisher information matrix (\cref{sec:fisher}), a common curvature matrix.

\switchcolumn[1]
\begin{example}[Probabilistic interpretation of the square loss]\label{ex:square_loss_probabilistic}
  For the square loss from \Cref{ex:square_loss}, we have that $c(\vf, \vy) = - \log( \mathrm{const.}
  \cdot \gN(\rvy \mid \vmu = f(\vx, \vtheta), \mSigma = \mI))$ where $\gN(\bullet \mid \vmu, \mSigma)$ is a multivariate Gaussian distribution with mean $\vmu \in \sR^C$ and positive definite covariance $\mSigma \in \sR^{C \times C}$,
  \begin{align*}
    \gN(\rvy \mid \vmu, \mSigma)
    =
    \frac{
    \exp\left( -\frac{1}{2} {(\rvy - \vmu)}^\top \mSigma^{-1} (\rvy - \vmu) \right)
    }{{(2\pi)}^{C/2} \sqrt{\det(\mSigma)}}\,.
  \end{align*}
  We can safely neglect the constant factor for the optimization problem and, by setting the covariance to the identity matrix and the mean to the neural net's prediction, identify that empirical risk minimization with square loss corresponds to maximum likelihood estimation of a Gaussian likelihood with unit covariance and mean parameterized by the network:
  \begin{align*}
    c                             & = \text{\texttt{MSELoss}}
    \\
                                  & \Leftrightarrow
    \\
    r(\rvy \mid f(\rvx, \vtheta)) & = \gN(\rvy \mid \vmu = f(\vx, \vtheta), \mSigma = \mI)\,
    \\
                                  & \Leftrightarrow
    \\
    p(\rvy \mid \rvx, \vtheta)    & = \gN(\rvy \mid \vmu = f(\vx, \vtheta), \mSigma = \mI)\,.
  \end{align*}
\end{example}

\begin{example}[Probabilistic interpretation of cross-entropy loss]\label{ex:cross_entropy_loss_probabilistic}
  For cross-entropy loss from \Cref{ex:cross_entropy_loss}, we have that $c(\vf, y) = - \log( \gC(\ry \mid \vsigma = \softmax(\vf) ))$ where $\gC(\bullet \mid \vsigma)$ is a categorical distribution over $\{1, \dots, C\}$ with probabilities $\vsigma \in \sR^C_{\ge 0}$ and $\vsigma^\top \vone = 1$,
  \begin{align*}
    \gC(\ry \mid \vsigma)
    =
    \prod_{c=1}^C [\vsigma]_c^{\delta_{\ry,c}}\,.
  \end{align*}
  Hence, we can identify that empirical risk minimization with softmax cross-entropy loss amounts to maximum likelihood estimation with a categorical likelihood parameterized by the softmax of the network's output:
  \begin{align*}
    c                             & = \text{\texttt{CrossEntropyLoss}}
    \\
                                  & \Leftrightarrow
    \\
    r(\ry \mid f(\rvx, \vtheta)) & = \gC(\ry \mid \vsigma = \softmax(f(\vx, \vtheta)))\,
    \\
                                  & \Leftrightarrow
    \\
    p(\ry \mid \rvx, \vtheta)    & = \gC(\ry \mid \vsigma = \softmax(f(\vx, \vtheta)))\,.
  \end{align*}
\end{example}

\codeblock{basics/label_sampling}
\switchcolumn[0]
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
